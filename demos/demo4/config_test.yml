dataset_path: ./local/data/demo4
gpu list: 0

visual:
    items:
        input_path: images
        output_path: visual_embeddings
        model: [
            # { name: VGG19,  output_layers: classifier.3, reshape: [224, 224], backend: torch, mean: [0.51, 0.51, 0.51], std: [0.12, 0.12, 0.12]},
            # { name: VGG19,  output_layers: classifier.3, reshape: [224, 224], backend: torch, preprocessing: biscotto, mean: [0.51, 0.51, 0.51], std: [0.12, 0.12, 0.12]},
#            { name: VGG19,  output_layers: classifier.3, reshape: [224, 224], backend: torch, preprocessing: zscore, mean: [0.51, 0.51, 0.51], std: [0.12, 0.12, 0.12]},
            { model_name: VGG19,  output_layers: classifier.4, reshape: [224, 224], backend: torch, preprocessing: zscore, mean: [0.1, 0.1, 0.1], std: [0.2, 0.2, 0.2]},
            { model_name: ResNet50,  output_layers: avgpool, reshape: [224, 224], backend: torch, preprocessing: zscore},
            { model_name: ResNet18,  output_layers: avgpool, reshape: [224, 224], backend: torch, preprocessing: zscore},
            { model_name: "google/vit-base-patch16-224-in21k",  output_layers: 1, backend: transformers, preprocessing: zscore},
            { model_name: Xception, output_layers: avg_pool, reshape: [299, 299], backend: tensorflow, preprocessing: minmax},
            { model_name: './demos/demo4/myModel.pt',  output_layers: avgpool, reshape: [28, 28], backend: torch, preprocessing: minmax},
            { model_name: vit_b_16,  output_layers: encoder.ln, reshape: [224, 224], backend: torch, preprocessing: minmax},
        ]
#
textual:
    items:
        input_path: descriptions.tsv
        output_path: textual_embeddings
        model: [
              { model_name: sentence-transformers/all-mpnet-base-v2,  output_layers: 1, clear_text: True, backend: sentence_transformers},
              { model_name: 'bert-base-uncased', tokenizer_name: 'bert-base-uncased', output_layers: 'pooler_output', clear_text: True, backend: transformers},
              { model_name: 'gpt2', tokenizer_name: 'gpt2', output_layers: 'last_hidden_state', clear_text: True, backend: transformers},
              { model_name: 'bert-base-cased', tokenizer_name: 'bert-base-cased', output_layers: 'pooler_output', clear_text: True, backend: transformers},
              { model_name: 'albert-base-v2', tokenizer_name: 'albert-base-v2', output_layers: 'pooler_output', clear_text: True, backend: transformers},
              { model_name: 'facebook/bart-large', tokenizer_name: 'facebook/bart-large', output_layers: 'last_hidden_state', clear_text: True, backend: transformers}, # no pooler
              { model_name: 'roberta-base', tokenizer_name: 'roberta-base', output_layers: 'pooler_output', clear_text: True, backend: transformers}
          ]

visual_textual:
    items:
        input_path: {visual: images, textual: descriptions.tsv}
        output_path: {visual: visual_embeddings, textual: textual_embeddings}
        model: [
            { model_name: openai/clip-vit-base-patch32, fusion: concat, backend: transformers, output_layers: 1, tokenizer: '', image_processor: '', resize: [224, 224]},
            { model_name: kakaobrain/align-base, fusion: concat, backend: transformers, output_layers: 1, tokenizer: '', image_processor: '', resize: [224, 224]}
        ]